# ROC & AUC

## Uses:

To find the best model and thresh-hold value for that model.

## ROC 
Roc used to find calculate the AUC

(Sensitivity) True positive Rate = True Positive /(True Positive + False Negative)
(1-Specificity) False positive Rate = False Positive /(False Positive + True Negative)

(Precision) False positive Rate = True Positive /(True Positive + False Positive)
when data more in any one of the classification then instead of (1-soecificity ) need to use precision
## AUC
AUC known as Area Under Curve amoung multiple model which has the higher AUC that is concidered as best model for our dataset

## ðŸ”— Links

[![linkedin](https://img.shields.io/badge/linkedin-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/naveenprabaharan-selvaraj-86771016b/)
